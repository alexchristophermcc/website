<!DOCTYPE HTML>
<!--
	Dimension by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>alex portfolio</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<div class="logo">
							
						</div>
						<div class="content">
							<div class="inner">
								<h1>ALEX CHRISTOPHER M</h1>
								<p>Innovating with Python in data science studies.<br />
									second-year student at Madras Christian College.</p>
							</div>
						</div>
						<nav>
							<ul>
								<li><a href="#work">Project</a></li>
								<li><a href="#intro">Internship</a></li>
								<li><a href="#introo">Achievement</a></li>
								
								
								
								<!--<li><a href="#elements">Elements</a></li>-->
							</ul>
						</nav>
					</header>

				<!-- Main -->
					<div id="main">

						<!-- Intro -->
							<article id="intro">
								<h2 class="major">Internship</h2>
								<span class="image main"><img src="images/certificate.png" alt="" /></span>
								<h3>Internship Experience</h3>
								<p>During my summer internship with <b>Uvakai</b>, I focused on analyzing the Radhapuram and Annamanadi canal systems, which include 194 lakes. My primary tasks involved data collection, cleaning, integration, and visualization. I sourced data from the Water Body Information System (WBIS) and meticulously organized it into separate Excel files for each lake. Using Python, I performed data cleaning to remove duplicates and standardize column names. I then merged and integrated these datasets to create a comprehensive view of the canal system, ensuring consistent and accurate data for analysis.</p>
								<p>In the data visualization phase, I leveraged Power BI to create interactive dashboards and Synoptic Designer to develop custom maps. The visualizations highlighted key insights such as capacity flow, monsoon impacts, and lake clustering. The Power BI dashboard featured an interactive map and detailed tables, allowing users to explore lake data efficiently. This project not only enhanced my technical skills in Python and Power BI but also provided valuable insights into water resource management, facilitating informed decision-making for stakeholders.</p>
								<p>Click on the PDF icon to view my detailed internship report stored on Google Drive. This report covers all aspects of my work, including data collection, cleaning, integration, and visualization.</p>
								<a href="https://drive.google.com/file/d/1Fl1GNJ_miMbY__DO19Fo7G7mI2C3_9Tu/view?usp=sharing"><img src="images/small.PNG"></a>
							</article>

							<article id="introo">
								<h2 class="major">Achievement</h2>
								<span class="image main"><img src="images/dslr copy.jpeg" alt="" /></span>
								<h3>A Journey through Anvaya 23</h3>
								<p>I participated in Anvaya 23, a national level technical symposium conducted by the MCA department of Ethiraj College for Women, an autonomous institution affiliated with the University of Madras and re-accredited with A+ by NAAC. In the CodeCraft event, I secured second place. The competition took place on 18th and 19th October 2023 and involved two rounds. The preliminary round consisted of multiple-choice questions based on Python programming, which I successfully cleared. In the mains, we were given 10 programs to code and solve, ensuring they passed 5 among all 10 test cases. This achievement highlights my programming skills and ability to perform under pressure in a competitive environment.</p>
								<span class="image main"><img src="images/envaya.jpg" alt="" /></span>
							</article>

						<!-- Work -->
							<article id="work">
								<h2 class="major">Project</h2>
								<p>1. "Custom Natural Language Processing with Python: A Non-NLTK Approach"</p>
								<p>2. "OTT Platform's Recommendation System Based on User Preferences"</p>
								<p>3. "Python-Powered Lake Analysis: Data Preprocessing, Integration, Transformation, and Visualization for Water Body Management"</p>
								<p>4. "Innovative Approach to Armstrong Number Verification Using Python"</p>
								<p>5. "Custom Implementation of Pearson Correlation Coefficient in Python"</p>
								<p>6. "Automating Data Extraction from PDF Using Python for Efficient Pastor's Address Management"</p>
								<p>7. "Comparative Analysis of Machine Learning Models for OTT Platform Recommendation"</p>
								<p>8. "Data Analysis of Tourist Places & Preferences Using Python"</p>
								

								<h3><u>Custom Natural Language Processing with Python: A Non-NLTK Approach</u></h3>
								<p>In my Natural Language Processing (NLP) project, I focused on analyzing user-provided 10-line paragraphs using various techniques. With NLTK library, I implemented tokenization, sentence and word tokenization, frequency distribution, stop words removal, punctuation elimination, stemming, lemmatization, and bag of words representation. Beyond NLTK, I innovated by applying list operations to achieve similar results independently. This project aimed to enhance my understanding and skills in NLP methodologies. Additionally, I integrated the pyttsx3 library to convert text into voice audio, adding a practical dimension to the project's output. Below, you can find the link to view the detailed project report in PDF format, and the GitHub repository link to access the project code.</p>
								<p><a href="https://drive.google.com/file/d/1-bIY-Z_k_X7SRAMym1o2FpjDwLsWhSPU/view?usp=drive_link"><img src="images/small.PNG"></a>&nbsp; &nbsp; <a href="https://github.com/alexchristophermcc/Custom-Natural-Language-Processing-with-Python-A-Non-NLTK-Approach"><img src="images/git logo.PNG"></a></p>

								<h3><u>OTT Platform's Recommendation System Based on User Preferences</u></h3>
								<p>In this project, I developed a recommendation system using Python to predict the preferred category of movies for users based on their reviews of five different OTT platforms: Netflix, Amazon Prime, Disney+ Hotstar, JioCinema, and ZEE5. The user dataset consisted of categorical data indicating their ratings (Useful, Moderate, and Can't Relate) for each of these OTT platforms, along with their preferred movie categories such as fiction, action, thriller, etc. To build the recommendation system, I first evaluated multiple machine learning algorithms to identify the one that provided the highest accuracy for our dataset. Once the optimal algorithm was selected, I trained the model using the collected user data. The model was then capable of predicting a user's preferred movie category based on their reviews of the OTT platforms. This recommendation system aims to personalize the viewing experience by suggesting movie genres that align with the user's preferences, making it easier for them to find content they are likely to enjoy. Below, you can find the link to view the detailed project report in PDF format and the GitHub repository link to access the project code.</p>
								<p><a href="https://drive.google.com/file/d/1BnMJ8KQG-i7zqzHk-2cJAs2UC0FGZFKS/view?usp=sharing"><img src="images/small.PNG"></a>&nbsp; &nbsp; <a href="https://github.com/alexchristophermcc/OTT-Platform-s-Recommendation-System-Based-on-User-Preferences"><img src="images/git logo.PNG"></a></p>

								<h3><u>Python-Powered Lake Analysis: Data Preprocessing, Integration, Transformation, and Visualization for Water Body Management</u></h3>
								<p>In this project, we utilized Python for comprehensive lake analysis, covering data preprocessing, integration, transformation, and visualization for effective water body management. Python played a crucial role in each stage, streamlining processes and saving significant time during our internship.

									Data Preprocessing:
									We employed Python for data cleaning tasks, such as removing duplicates, cleaning rows and columns, and renaming columns to ensure uniformity across datasets. This step was essential for maintaining data integrity and consistency.
									
									Data Integration:
									Python was used to integrate the datasets by merging them based on a common date reference, resulting in uniform rows and columns. This step enabled us to create a cohesive dataset that was easy to manage and analyze.
									
									Data Transformation:
									The transformation phase involved combining all merged datasets into a single comprehensive dataset, which was then exported as an Excel file. This unified dataset provided a complete view of the lake data, facilitating further analysis.
									
									Data Visualization:
									While Power BI was the primary tool for visualization, Python was also used for preliminary data visualization to verify the accuracy of data frames before deploying them to Power BI. This step ensured the reliability of the visual representations.
									
									A key aspect of the project was the use of Python's global function to dynamically create variables. Given the need to handle data for 194 lakes, manually creating variables for each lake would have been impractical. By using a global function within a loop that iterated 194 times, we efficiently generated variables, demonstrating the power and flexibility of Python in handling large-scale data analysis tasks.
									
									Overall, Python significantly enhanced our internship experience by automating repetitive tasks, ensuring data accuracy, and providing a robust platform for data analysis. Below, you can find the link to view the detailed project report GitHub repository link to access the project code.
									</p>
								<p><a href="https://github.com/alexchristophermcc/Python-Powered-Lake-Analysis"><img src="images/git logo.PNG"></a></p>

								<h3><u>Innovative Approach to Armstrong Number Verification Using Python</u></h3>
								<p>In this project, I developed an innovative Python program to verify Armstrong numbers, deviating from the traditional mathematical methods involving remainders, quotients, and division. Instead, I employed a string manipulation approach to achieve the same result.

									The process begins by converting the input number into a string format. Once in string form, the number is split into individual digits. Each digit, now a character, is then converted back into an integer. The program then raises each digit to the power corresponding to the number of digits in the original number (e.g., cubes for three-digit numbers, fourth powers for four-digit numbers, etc.).
									
									Each of these powered values is appended to a list. Once all digits have been processed, the program calculates the sum of the list elements. If this sum equals the original input number, the number is identified as an Armstrong number; otherwise, it is not.
									
									This method showcases an innovative application of string manipulation and list operations in Python, providing a fresh perspective on solving the Armstrong number problem. Below, you can find the link to view the detailed project report in the GitHub repository link to access the project code.</p>
								<p><a href="https://github.com/alexchristophermcc/Armstrong-Number"><img src="images/git logo.PNG"></a></p>

								<h3><u>Custom Implementation of Pearson Correlation Coefficient in Python</u></h3>
								<p>In this project, I developed a custom implementation of the Pearson correlation coefficient using Python. Driven by my interest in statistics, I chose not to rely on existing libraries or functions. Instead, I used integer values, list operations, and basic arithmetic to manually compute the correlation.

									The process involves calculating the mean, variance, and covariance of the data sets, and then using these values to determine the Pearson correlation coefficient. The program then interprets the coefficient to indicate whether the data sets have a positive correlation, negative correlation, or no correlation.
									
									This project showcases my ability to apply fundamental programming techniques and mathematical concepts to solve statistical problems in Python. Below, you can find the link to view the detailed project report in PDF format.</p>
								<p><a href="https://drive.google.com/file/d/13dbTpB87R76BxuPXL36rxANyxRZArLXu/view?usp=sharing"><img src="images/small.PNG"></a></p>

								<h3><u>Automating Data Extraction from PDF Using Python for Efficient Pastor Address Management</u></h3>
								<p>To automate the data extraction process from a PDF containing pastors' addresses, I developed a Python program utilizing string separation techniques. The input consisted of a text extracted from the PDF, containing addresses of 1582 pastors, each preceded by a unique identifier from 001 to 1582. I generated a list of these identifiers to locate and split the data. The program looped through the text, splitting it at each occurrence of an identifier and storing the resulting segments in a list. This automated approach efficiently replaced the manual copy-paste method, significantly speeding up the data extraction process.Below, you can find the link to view the detailed project report in the GitHub repository link to access the project code.</p>
								<p><a href="https://drive.google.com/file/d/13BBW1RSezHxahMjcMxvAJsKvYKD6EeOI/view?usp=sharing"><img src="images/small.PNG"></a>&nbsp; &nbsp; <a href="https://github.com/alexchristophermcc/Automating-Data-Extraction-from-PDF-Using-Python-for-Efficient-Pastor-Address-Management"><img src="images/git logo.PNG"></a></p>

								<h3><u>Comparative Analysis of Machine Learning Models for OTT Platform Recommendation</u></h3>
								<p>In the project "Comparative Analysis of Machine Learning Models for OTT Platform Recommendation," I used a dataset featuring user preferences for five OTT platforms (Netflix, Amazon Prime, Disney+ Hotstar, JioCinema, and ZEE5), categorized as Useful, Moderate, or Cannot Relate. Data preprocessing included handling null values and converting categorical string data to numerical values. The transformed data for the five OTT platforms were concatenated into a single dataframe. The x-axis data consisted of user opinions on the platforms, while the y-axis data represented the most preferred OTT platform. I implemented and compared six machine learning algorithms: Decision Tree Classifier, Gaussian Naive Bayes, Logistic Regression, K-Nearest Neighbor, Support Vector Machine (SVM), and Random Forest Classifier. The SVM algorithm achieved the highest accuracy at 58%, outperforming the others.</p>
								<p><a href="https://drive.google.com/file/d/1g9uv1H5dWhopyxLJz02quS0a_yJ0Vs0W/view?usp=sharing"><img src="images/small.PNG"></a>&nbsp; &nbsp; <a href="https://github.com/alexchristophermcc/Comparative-Analysis-of-Machine-Learning-Models-for-OTT-Platform-Recommendation"><img src="images/git logo.PNG"></a></p>

								<h3><u>Data Analysis of Tourist Places & Preferences Using Python</u></h3>
								<p>In the project "Data Analysis of Tourist Places and Preferences using Python," I collected data through a Google form with questions such as name, gender, favorite place, travel preferences, reasons for enjoying the place, visit frequency, distance from home, suggested activities, and place ratings. Data cleaning involved removing unused columns and null values. Data integration included eliminating irrelevant data, and data transformation categorized visit frequencies into "once a week," "once a month," and "once a year." The analysis was visualized using pie charts, bar charts, and scatter plots to provide various insights.</p>
								<p><a href="https://drive.google.com/file/d/1o0jt2jLNqQGEViVSGupXuOXb8Jly5p1b/view?usp=sharing"><img src="images/small.PNG"></a>&nbsp; &nbsp; <a href="https://github.com/alexchristophermcc/Data-Analysis-of-Tourist-Places-Preferences-Using-Python"><img src="images/git logo.PNG"></a></p>
							</article>

						<!-- About -->
							<article id="about">
								<h2 class="major">About</h2>
								<span class="image main"><img src="images/pic03.jpg" alt="" /></span>
								<p>Lorem ipsum dolor sit amet, consectetur et adipiscing elit. Praesent eleifend dignissim arcu, at eleifend sapien imperdiet ac. Aliquam erat volutpat. Praesent urna nisi, fringila lorem et vehicula lacinia quam. Integer sollicitudin mauris nec lorem luctus ultrices. Aliquam libero et malesuada fames ac ante ipsum primis in faucibus. Cras viverra ligula sit amet ex mollis mattis lorem ipsum dolor sit amet.</p>
							</article>

						<!-- Contact -->
							<article id="contact">
								<h2 class="major">Contact</h2>
								<form method="post" action="#">
									<div class="fields">
										<div class="field half">
											<label for="name">Name</label>
											<input type="text" name="name" id="name" />
										</div>
										<div class="field half">
											<label for="email">Email</label>
											<input type="text" name="email" id="email" />
										</div>
										<div class="field">
											<label for="message">Message</label>
											<textarea name="message" id="message" rows="4"></textarea>
										</div>
									</div>
									<ul class="actions">
										<li><input type="submit" value="Send Message" class="primary" /></li>
										<li><input type="reset" value="Reset" /></li>
									</ul>
								</form>
								<ul class="icons">
									<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
									<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
									<li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
									<li><a href="#" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
								</ul>
							</article>



							</article>

					</div>

				<!-- Footer -->
					<footer id="footer">
						<p class="copyright">&nbsp;<br>&nbsp;<br>&nbsp;<br>&nbsp;<br>&nbsp;<br>&nbsp;<br>&nbsp;</p>
					</footer>

			</div>

		<!-- BG -->
			<div id="bg"></div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
